{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config = config)\n",
    "import keras\n",
    "from keras.datasets import cifar100\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Activation, MaxPooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 100 classes\n",
      "Class names: ['beaver', ' dolphin', ' otter', ' seal', ' whale', 'aquarium fish', ' flatfish', ' ray', ' shark', ' trout', 'orchids', ' poppies', ' roses', ' sunflowers', ' tulips', 'bottles', ' bowls', ' cans', ' cups', ' plates', 'apples', ' mushrooms', ' oranges', ' pears', ' sweet peppers', 'clock', ' computer keyboard', ' lamp', ' telephone', ' television', 'bed', ' chair', ' couch', ' table', ' wardrobe', 'bee', ' beetle', ' butterfly', ' caterpillar', ' cockroach', 'bear', ' leopard', ' lion', ' tiger', ' wolf', 'bridge', ' castle', ' house', ' road', ' skyscraper', 'cloud', ' forest', ' mountain', ' plain', ' sea', 'camel', ' cattle', ' chimpanzee', ' elephant', ' kangaroo', 'fox', ' porcupine', ' possum', ' raccoon', ' skunk', 'crab', ' lobster', ' snail', ' spider', ' worm', 'baby', ' boy', ' girl', ' man', ' woman', 'crocodile', ' dinosaur', ' lizard', ' snake', ' turtle', 'hamster', ' mouse', ' rabbit', ' shrew', ' squirrel', 'maple', ' oak', ' palm', ' pine', ' willow', 'bicycle', ' bus', ' motorcycle', ' pickup truck', ' train', 'lawn-mower', ' rocket', ' streetcar', ' tank', ' tractor']\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode = 'fine')\n",
    "\n",
    "class_names = []\n",
    "with open('cifar100_class_names') as file:\n",
    "    for line in file:\n",
    "        string = line.replace(' ', '')\n",
    "        string = line.replace('\\n', '')\n",
    "        string_list = string.split(',')\n",
    "        class_names = class_names + string_list\n",
    "print('There are totally', len(class_names), 'classes')\n",
    "print('Class names:', class_names)\n",
    "\n",
    "# preprocessing\n",
    "X_train = X_train / 255. # .reshape((X_train.shape[0], -1))\n",
    "X_test = X_test / 255. # .reshape((X_test.shape[0], -1))\n",
    "\n",
    "def reshape_func(data):\n",
    "    return data.reshape((data.shape[0], -1))\n",
    "\n",
    "# model\n",
    "def create_model(hidden_layers = [128, 64, 32], \n",
    "                 activations = ['relu', 'relu', 'relu', 'softmax'], \n",
    "                 weight_initializations = ['he_normal', 'he_normal', 'he_normal', 'he_normal'], \n",
    "                 learning_rate = 1e-5,\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 optimizer = 'adam', \n",
    "                 metrics = ['accuracy']):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layers[0], input_shape = (3072,), activation = activations[0], kernel_initializer = weight_initializations[0]))\n",
    "    for i in range(1, len(hidden_layers) - 1):\n",
    "        model.add(Dense(hidden_layers[i], activation = activations[i], kernel_initializer = weight_initializations[i]))\n",
    "    model.add(Dense(100, activation = activations[-1]))\n",
    "    model.compile(loss = loss, optimizer = optimizer, metrics = metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClassGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, X, y, batch_size = 32, n_classes = 100):\n",
    "        self.X, self.y = X, keras.utils.to_categorical(y, num_classes = n_classes)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X_batch = self.X[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        y_batch = self.y[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        \n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 4.2272 - acc: 0.0565\n",
      "Loss\tAccuracy\n",
      "10000/10000 [==============================] - 0s 47us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.0137492988586425, 0.0817]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_gen = DataClassGenerator(reshape_func(X_train), y_train, len(class_names))\n",
    "model = create_model()\n",
    "model.fit_generator(generator = class_gen, epochs = 1)\n",
    "print('Loss\\tAccuracy')\n",
    "model.evaluate(reshape_func(X_test), keras.utils.to_categorical(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_generator(X, y, batch_size = 32, n_classes = 100):\n",
    "    y = keras.utils.to_categorical(y_train, num_classes = n_classes)\n",
    "    \n",
    "    while 1:\n",
    "        for idx in range(int(np.ceil(len(X_train) / float(batch_size)))):\n",
    "            X_batch = X[idx * batch_size : (idx + 1) * batch_size]\n",
    "            y_batch = y[idx * batch_size : (idx + 1) * batch_size]\n",
    "            yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.1113 - acc: 0.0715\n",
      "Loss\tAccuracy\n",
      "10000/10000 [==============================] - 0s 47us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.849954206085205, 0.1099]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model = create_model()\n",
    "model.fit_generator(generator = func_generator(reshape_func(X_train), y_train, batch_size = batch_size), \n",
    "                    steps_per_epoch = int(np.ceil(len(X_train) / float(batch_size))), \n",
    "                    epochs = 1)\n",
    "print('Loss\\tAccuracy')\n",
    "model.evaluate(reshape_func(X_test), keras.utils.to_categorical(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 4.0863 - acc: 0.0796\n",
      "Loss\tAccuracy\n",
      "10000/10000 [==============================] - 1s 85us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5983389251708986, 0.1558]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "'''\n",
    "Image data format refers to the representation of batches of images. TensorFlow supports NHWC \n",
    "(TensorFlow default) and NCHW (cuDNN default). N refers to the number of images in a batch, \n",
    "H refers to the number of pixels in the vertical dimension, W refers to the number of pixels \n",
    "in the horizontal dimension, and C refers to the channels (e.g. 1 for black and white, 3 for \n",
    "RGB, etc.) Although cuDNN can operate on both formats, it is faster to operate in its default \n",
    "format.\n",
    "\n",
    "The best practice is to build models that work with both NCHW and NHWC as it is common to train\n",
    "using NCHW on GPU, and then do inference with NHWC on CPU.\n",
    "\n",
    "The very brief history of these two formats is that TensorFlow started by using NHWC because it \n",
    "was a little faster on CPUs. Then the TensorFlow team discovered that NCHW performs better when \n",
    "using the NVIDIA cuDNN library. The current recommendation is that users support both formats in \n",
    "their models. In the long term, we plan to rewrite graphs to make switching between the formats \n",
    "transparent.\n",
    "\n",
    "ref: https://www.tensorflow.org/performance/performance_guide#use_nchw_imag\n",
    "'''\n",
    "def create_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape = (32, 32, 3), kernel_initializer = 'normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), kernel_initializer = 'normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "    return model\n",
    "model = create_cnn()\n",
    "\n",
    "\n",
    "kerasGenerator = ImageDataGenerator(featurewise_center = False, \n",
    "                               samplewise_center = False, \n",
    "                               featurewise_std_normalization = False, \n",
    "                               samplewise_std_normalization = False, \n",
    "                               zca_whitening = False, \n",
    "                               zca_epsilon = 1e-06,\n",
    "                               rotation_range = 0.0, \n",
    "                               width_shift_range = 0.0, # Range for random horizontal shifts\n",
    "                               height_shift_range = 0.0, # Range for random vertical shifts\n",
    "                               brightness_range = None, \n",
    "                               shear_range = 0.2, # Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
    "                               zoom_range = 0.1, # Range for random zoom\n",
    "                               channel_shift_range = 0.0, \n",
    "                               fill_mode = 'nearest', \n",
    "                               cval = 0.0, \n",
    "                               horizontal_flip = True, \n",
    "                               vertical_flip = False, \n",
    "                               rescale = None, \n",
    "                               preprocessing_function = None, # Function that will be implied on each input\n",
    "                               data_format = None, # One of {'channel_first', 'channel_last'}\n",
    "                               validation_split = 0.0)\n",
    "kerasGenerator.fit(X_train, augment = True, rounds = 1)\n",
    "model.fit_generator(generator = kerasGenerator.flow(X_train, keras.utils.to_categorical(y_train), batch_size = 32), \n",
    "                    epochs = 1)\n",
    "print('Loss\\tAccuracy')\n",
    "model.evaluate(X_test, keras.utils.to_categorical(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
