{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia2014 + Gigaword5 and GloVe\n",
    "ref: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.Session(config = config)\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Conv1D, MaxPooling1D, LSTM, Flatten, Dense, Dropout, Reshape, Bidirectional, Conv2D, MaxPool2D, Concatenate, Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_NB_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "VALIDATION_SPLIT = 0.3\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = datapath('/workspace/2018_data_science/word2vec/model/glove.6B/glove.6B.300d.txt')\n",
    "tmp_file = get_tmpfile(\"word2vec.6B.300d.txt\")\n",
    "\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " (300,),\n",
       " array([ 0.25653  ,  0.66592  , -0.5313   ,  0.20342  ,  0.40049  ,\n",
       "        -0.23473  ,  0.09909  ,  0.057834 , -0.12077  , -1.1298   ,\n",
       "         0.35164  , -0.3265   , -0.66833  ,  0.18788  ,  0.22281  ,\n",
       "         0.054691 ,  0.025744 ,  0.31266  , -0.28724  ,  0.23793  ,\n",
       "        -0.040331 ,  0.32854  ,  0.22044  ,  0.45647  , -0.37563  ,\n",
       "         0.43402  ,  0.38154  , -0.35248  ,  0.19495  ,  0.4076   ,\n",
       "        -0.37865  ,  0.23548  , -0.84291  , -0.49411  ,  0.052115 ,\n",
       "        -0.16012  ,  0.64314  ,  0.30405  , -0.43855  , -0.24154  ,\n",
       "        -0.24044  , -0.23007  ,  0.1408   , -0.53307  , -0.5172   ,\n",
       "        -0.064734 , -0.12548  ,  0.078003 ,  0.36785  ,  0.24616  ,\n",
       "        -0.16876  ,  0.50944  , -0.055875 ,  0.11483  ,  0.29215  ,\n",
       "        -0.029616 ,  0.094811 ,  0.024069 , -0.63261  , -0.40383  ,\n",
       "        -0.20841  ,  0.039754 ,  0.58189  ,  0.11466  , -0.335    ,\n",
       "        -0.27225  , -0.2824   , -0.5118   ,  0.22429  ,  0.456    ,\n",
       "        -0.15358  ,  0.70428  ,  0.30294  , -0.20955  , -0.011789 ,\n",
       "         0.29492  ,  0.18952  ,  0.031591 ,  0.12141  ,  0.65948  ,\n",
       "         0.14449  , -0.17718  , -0.38307  ,  0.14447  , -0.10626  ,\n",
       "        -0.43811  ,  0.043725 ,  0.20719  , -0.52765  , -0.16038  ,\n",
       "        -0.26498  , -0.24922  ,  0.27571  ,  0.10185  , -0.002841 ,\n",
       "         0.44867  ,  0.14924  ,  0.0026418, -0.51966  , -0.30382  ,\n",
       "         0.44992  ,  0.14053  , -0.045289 ,  0.15192  , -0.03029  ,\n",
       "         0.20464  , -0.098525 ,  0.11547  ,  0.29337  ,  0.87538  ,\n",
       "         0.033805 , -0.023913 , -1.0737   ,  0.14058  ,  0.2333   ,\n",
       "         0.43979  ,  0.015073 ,  0.4834   , -0.047389 ,  0.26837  ,\n",
       "        -1.0796   ,  0.36589  , -0.059518 ,  0.4625   , -0.49777  ,\n",
       "         0.14285  , -0.49198  ,  0.52663  , -0.1024   , -0.22362  ,\n",
       "         0.6845   , -0.28364  ,  0.20222  ,  0.4528   , -0.37129  ,\n",
       "        -0.30313  ,  0.43129  , -0.16782  , -0.14972  ,  0.77987  ,\n",
       "        -0.052025 ,  0.13599  , -0.024823 , -0.66856  ,  0.15082  ,\n",
       "         0.12765  , -0.021816 ,  0.03224  , -0.22332  ,  0.021629 ,\n",
       "         0.069325 ,  0.5422   , -0.19016  , -0.30067  ,  0.17118  ,\n",
       "         0.23501  , -0.21868  ,  0.053248 , -0.23874  ,  0.072883 ,\n",
       "         0.41495  ,  0.40858  ,  0.27456  , -0.16156  ,  0.2638   ,\n",
       "         0.014453 ,  0.24392  , -0.50145  , -0.31703  ,  0.21059  ,\n",
       "        -0.045762 , -0.039115 ,  0.19433  ,  0.5992   ,  0.042563 ,\n",
       "        -0.12242  ,  0.32646  , -0.40515  ,  0.013263 , -0.56558  ,\n",
       "         0.19984  , -0.19897  , -0.49579  , -0.36991  , -0.1801   ,\n",
       "        -0.22557  ,  0.0028445, -0.25334  ,  0.55909  , -0.56835  ,\n",
       "        -0.46967  ,  0.060974 , -0.41322  , -0.24996  , -0.2846   ,\n",
       "         0.19745  , -0.099387 , -0.24678  , -0.53946  ,  0.31609  ,\n",
       "         0.77105  , -0.32183  ,  0.36139  , -0.087025 ,  0.56626  ,\n",
       "         0.76486  , -0.14512  , -0.11135  , -0.14413  ,  0.53016  ,\n",
       "         0.13376  , -0.27582  , -0.13206  , -0.65733  ,  0.058188 ,\n",
       "         0.38301  ,  0.056686 ,  0.16166  ,  0.27458  ,  0.17245  ,\n",
       "        -0.29459  ,  0.096297 , -0.50513  , -0.52786  , -0.10126  ,\n",
       "         0.16703  , -0.069054 , -0.093596 , -0.038444 ,  0.43208  ,\n",
       "         0.59946  ,  0.074329 ,  0.11863  , -0.35532  ,  0.20506  ,\n",
       "         0.20253  , -0.029247 , -0.2725   , -0.56084  ,  0.13691  ,\n",
       "        -0.39489  , -0.078846 , -0.29338  , -0.19379  , -1.5217   ,\n",
       "         0.19236  ,  0.13664  , -0.21657  ,  0.02523  ,  0.67897  ,\n",
       "        -0.33233  , -0.30611  ,  0.091359 , -0.012469 ,  0.9518   ,\n",
       "         0.75772  ,  0.27005  , -0.49594  , -0.44736  ,  0.034779 ,\n",
       "        -0.21821  , -0.44495  , -0.046993 , -0.21626  , -0.054053 ,\n",
       "         0.49918  , -0.33855  ,  0.42897  , -0.55699  ,  0.42398  ,\n",
       "        -0.065681 ,  0.24518  ,  0.0066384, -0.22098  , -0.26532  ,\n",
       "         0.49813  , -1.949    ,  0.26658  ,  0.11726  ,  0.037159 ,\n",
       "        -0.51818  , -0.14344  ,  0.0050575,  0.32357  , -0.75793  ,\n",
       "         0.12188  ,  0.34378  ,  0.015168 ,  0.20838  , -0.08412  ,\n",
       "         0.020308 , -0.51858  , -0.23014  , -0.53273  , -0.17938  ,\n",
       "        -0.14921  ,  0.2404   ,  0.22182  ,  0.68883  , -0.018991 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model['animal']), model['animal'].shape, model['animal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('france', 1.0),\n",
       " ('french', 0.7344760894775391),\n",
       " ('paris', 0.6580672264099121),\n",
       " ('belgium', 0.620672345161438),\n",
       " ('spain', 0.573593258857727),\n",
       " ('italy', 0.5643459558486938),\n",
       " ('germany', 0.5567397475242615),\n",
       " ('prohertrib', 0.5564222931861877),\n",
       " ('britain', 0.5553334951400757),\n",
       " ('chirac', 0.5362644195556641)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector(model['france'], topn = 10, restrict_vocab = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.6713277101516724),\n",
       " ('princess', 0.5432624220848083),\n",
       " ('throne', 0.5386104583740234),\n",
       " ('monarch', 0.5347574949264526),\n",
       " ('daughter', 0.498025119304657),\n",
       " ('mother', 0.4956442713737488),\n",
       " ('elizabeth', 0.4832652509212494),\n",
       " ('kingdom', 0.47747087478637695),\n",
       " ('prince', 0.4668239951133728),\n",
       " ('wife', 0.4647327661514282)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive = ['woman', 'king'], negative = ['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match('breakfast cereal dinner lunch'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pca_plot(model):\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = PCA(n_components = 2)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    for i in range(len(x)):\n",
    "        label = labels[i]\n",
    "        if label in ['king', 'queen', 'sister', 'brother', 'niece', 'nephew', 'aunt', 'uncle', 'woman', 'man', \n",
    "                     'madam', 'sir']:\n",
    "            plt.scatter(x[i],y[i])\n",
    "            plt.annotate(label,\n",
    "                         xy = (x[i], y[i]),\n",
    "                         xytext = (5, 2),\n",
    "                         textcoords = 'offset points',\n",
    "                         ha = 'right',\n",
    "                         va = 'bottom')\n",
    "    plt.show()\n",
    "\n",
    "pca_plot(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuter-21578 Data set with word2vec\n",
    "Last week, you have already worked on Reuters-21578 dataset for multi-class classification. This week, you are using word2vec to classify the same dataset.\n",
    "\n",
    "In this lab, you will have to implement 3 three neural network model using keras API:\n",
    "1. Mutilayer perceptron\n",
    "2. Conv1D\n",
    "3. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this requires download from the first time\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = MAX_NB_WORDS, \n",
    "                                                         skip_top = 0, \n",
    "                                                         maxlen = MAX_SEQUENCE_LENGTH,\n",
    "                                                         seed = 113,\n",
    "                                                         start_char = 1, \n",
    "                                                         oov_char = 2, \n",
    "                                                         index_from = 3)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "word2index = reuters.get_word_index()\n",
    "word2index = {key : (value + 3) for (key, value) in word2index.items()}\n",
    "word2index['<PAD>'] = 0\n",
    "word2index['<START>'] = 1\n",
    "word2index['<UNK>'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join('./model/glove.6B/', 'glove.6B.300d.txt'), encoding = 'utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_matrix = np.zeros((len(word2index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word2index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(len(word2index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length = MAX_SEQUENCE_LENGTH,\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen = MAX_SEQUENCE_LENGTH)\n",
    "X_test = pad_sequences(X_test, maxlen = MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train tensor: (7976, 300)\n",
      "Shape of X_test tensor: (1994, 300)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train tensor:', X_train.shape)\n",
    "print('Shape of X_test tensor:', X_test.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_train = X_train[indices]\n",
    "y_train = y_train[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * X_train.shape[0])\n",
    "\n",
    "X_val = X_train[-nb_validation_samples:]\n",
    "y_val = y_train[-nb_validation_samples:]\n",
    "X_train = X_train[:-nb_validation_samples]\n",
    "y_train = y_train[:-nb_validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + multiple layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 300, 300)          9294900   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 90000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               11520128  \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 46)                1518      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 46)                0         \n",
      "=================================================================\n",
      "Total params: 20,826,882\n",
      "Trainable params: 11,531,982\n",
      "Non-trainable params: 9,294,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5584 samples, validate on 2392 samples\n",
      "Epoch 1/20\n",
      "5584/5584 [==============================] - 1s 176us/step - loss: 2.2603 - acc: 0.5021 - val_loss: 1.6975 - val_acc: 0.6070\n",
      "Epoch 2/20\n",
      "5584/5584 [==============================] - 0s 29us/step - loss: 1.2325 - acc: 0.7085 - val_loss: 1.5083 - val_acc: 0.6777\n",
      "Epoch 3/20\n",
      "5584/5584 [==============================] - 0s 31us/step - loss: 0.7337 - acc: 0.8164 - val_loss: 1.4167 - val_acc: 0.7003\n",
      "Epoch 4/20\n",
      "5584/5584 [==============================] - 0s 30us/step - loss: 0.4590 - acc: 0.8811 - val_loss: 1.4577 - val_acc: 0.7057\n",
      "Epoch 5/20\n",
      "5584/5584 [==============================] - 0s 31us/step - loss: 0.2988 - acc: 0.9282 - val_loss: 1.5174 - val_acc: 0.7065\n",
      "Epoch 6/20\n",
      "5584/5584 [==============================] - 0s 30us/step - loss: 0.2182 - acc: 0.9542 - val_loss: 1.6141 - val_acc: 0.7023\n",
      "Epoch 7/20\n",
      "5584/5584 [==============================] - 0s 30us/step - loss: 0.1778 - acc: 0.9628 - val_loss: 1.7515 - val_acc: 0.6931\n",
      "Epoch 8/20\n",
      "5584/5584 [==============================] - 0s 32us/step - loss: 0.1490 - acc: 0.9651 - val_loss: 1.8467 - val_acc: 0.6940\n",
      "Epoch 9/20\n",
      "5584/5584 [==============================] - 0s 31us/step - loss: 0.1329 - acc: 0.9672 - val_loss: 1.7781 - val_acc: 0.6865\n",
      "Epoch 10/20\n",
      "5584/5584 [==============================] - 0s 31us/step - loss: 0.1294 - acc: 0.9687 - val_loss: 1.7551 - val_acc: 0.6952\n",
      "Epoch 11/20\n",
      "5584/5584 [==============================] - 0s 30us/step - loss: 0.1145 - acc: 0.9688 - val_loss: 1.7875 - val_acc: 0.7090\n",
      "Epoch 12/20\n",
      "5584/5584 [==============================] - 0s 29us/step - loss: 0.1109 - acc: 0.9690 - val_loss: 1.9152 - val_acc: 0.6890\n",
      "Epoch 13/20\n",
      "5584/5584 [==============================] - 0s 31us/step - loss: 0.1118 - acc: 0.9690 - val_loss: 1.7449 - val_acc: 0.6906\n",
      "Epoch 14/20\n",
      "5584/5584 [==============================] - 0s 30us/step - loss: 0.1088 - acc: 0.9672 - val_loss: 1.9812 - val_acc: 0.6944\n",
      "Epoch 15/20\n",
      "5584/5584 [==============================] - 0s 31us/step - loss: 0.0966 - acc: 0.9694 - val_loss: 1.7404 - val_acc: 0.7111\n",
      "Epoch 16/20\n",
      "5584/5584 [==============================] - 0s 30us/step - loss: 0.0862 - acc: 0.9678 - val_loss: 1.9348 - val_acc: 0.6990\n",
      "Epoch 17/20\n",
      "5584/5584 [==============================] - 0s 30us/step - loss: 0.0850 - acc: 0.9687 - val_loss: 1.8596 - val_acc: 0.7099\n",
      "Epoch 18/20\n",
      "5584/5584 [==============================] - 0s 30us/step - loss: 0.0848 - acc: 0.9692 - val_loss: 1.9553 - val_acc: 0.7048\n",
      "Epoch 19/20\n",
      "5584/5584 [==============================] - 0s 30us/step - loss: 0.0858 - acc: 0.9687 - val_loss: 1.8851 - val_acc: 0.6936\n",
      "Epoch 20/20\n",
      "5584/5584 [==============================] - 0s 29us/step - loss: 0.0863 - acc: 0.9679 - val_loss: 1.8774 - val_acc: 0.7128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a181941d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape = (MAX_SEQUENCE_LENGTH,), dtype = 'int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "x = Flatten()(embedded_sequences)\n",
    "x = Dense(128)(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Dense(64)(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Dense(46)(x)\n",
    "preds = Activation('softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "print(model.summary())\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data = (X_val, y_val),\n",
    "          epochs = 20, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994/1994 [==============================] - 0s 48us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.102050429002691, 0.6825476429287863]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 300, 300)          9294900   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 296, 64)           96064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 59, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3776)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3776)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                241728    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 9,635,682\n",
      "Trainable params: 340,782\n",
      "Non-trainable params: 9,294,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5584 samples, validate on 2392 samples\n",
      "Epoch 1/30\n",
      "5584/5584 [==============================] - 2s 281us/step - loss: 3.0830 - acc: 0.3770 - val_loss: 2.3445 - val_acc: 0.4143\n",
      "Epoch 2/30\n",
      "5584/5584 [==============================] - 0s 55us/step - loss: 2.0851 - acc: 0.3797 - val_loss: 1.6539 - val_acc: 0.3988\n",
      "Epoch 3/30\n",
      "5584/5584 [==============================] - 0s 53us/step - loss: 1.6751 - acc: 0.4121 - val_loss: 1.5272 - val_acc: 0.5004\n",
      "Epoch 4/30\n",
      "5584/5584 [==============================] - 0s 51us/step - loss: 1.4148 - acc: 0.5826 - val_loss: 1.2464 - val_acc: 0.6873\n",
      "Epoch 5/30\n",
      "5584/5584 [==============================] - 0s 52us/step - loss: 1.1262 - acc: 0.7090 - val_loss: 1.1071 - val_acc: 0.7345\n",
      "Epoch 6/30\n",
      "5584/5584 [==============================] - 0s 53us/step - loss: 0.9271 - acc: 0.7525 - val_loss: 1.0684 - val_acc: 0.7467\n",
      "Epoch 7/30\n",
      "5584/5584 [==============================] - 0s 54us/step - loss: 0.7675 - acc: 0.7914 - val_loss: 1.0555 - val_acc: 0.7592\n",
      "Epoch 8/30\n",
      "5584/5584 [==============================] - 0s 55us/step - loss: 0.6474 - acc: 0.8202 - val_loss: 1.0756 - val_acc: 0.7642\n",
      "Epoch 9/30\n",
      "5584/5584 [==============================] - 0s 56us/step - loss: 0.5410 - acc: 0.8533 - val_loss: 1.1702 - val_acc: 0.7571\n",
      "Epoch 10/30\n",
      "5584/5584 [==============================] - 0s 56us/step - loss: 0.4648 - acc: 0.8657 - val_loss: 1.1904 - val_acc: 0.7592\n",
      "Epoch 11/30\n",
      "5584/5584 [==============================] - 0s 55us/step - loss: 0.3960 - acc: 0.8850 - val_loss: 1.1260 - val_acc: 0.7763\n",
      "Epoch 12/30\n",
      "5584/5584 [==============================] - 0s 54us/step - loss: 0.3322 - acc: 0.9097 - val_loss: 1.1422 - val_acc: 0.7738\n",
      "Epoch 13/30\n",
      "5584/5584 [==============================] - 0s 53us/step - loss: 0.3078 - acc: 0.9140 - val_loss: 1.1965 - val_acc: 0.7709\n",
      "Epoch 14/30\n",
      "5584/5584 [==============================] - 0s 52us/step - loss: 0.2782 - acc: 0.9178 - val_loss: 1.1870 - val_acc: 0.7751\n",
      "Epoch 15/30\n",
      "5584/5584 [==============================] - 0s 53us/step - loss: 0.2578 - acc: 0.9259 - val_loss: 1.2038 - val_acc: 0.7809\n",
      "Epoch 16/30\n",
      "5584/5584 [==============================] - 0s 51us/step - loss: 0.2352 - acc: 0.9300 - val_loss: 1.2494 - val_acc: 0.7772\n",
      "Epoch 17/30\n",
      "5584/5584 [==============================] - 0s 52us/step - loss: 0.2267 - acc: 0.9352 - val_loss: 1.1740 - val_acc: 0.7730\n",
      "Epoch 18/30\n",
      "5584/5584 [==============================] - 0s 51us/step - loss: 0.2060 - acc: 0.9404 - val_loss: 1.2214 - val_acc: 0.7843\n",
      "Epoch 19/30\n",
      "5584/5584 [==============================] - 0s 52us/step - loss: 0.1741 - acc: 0.9481 - val_loss: 1.3496 - val_acc: 0.7801\n",
      "Epoch 20/30\n",
      "5584/5584 [==============================] - 0s 50us/step - loss: 0.1642 - acc: 0.9497 - val_loss: 1.3016 - val_acc: 0.7805\n",
      "Epoch 21/30\n",
      "5584/5584 [==============================] - 0s 50us/step - loss: 0.1634 - acc: 0.9486 - val_loss: 1.3331 - val_acc: 0.7818\n",
      "Epoch 22/30\n",
      "5584/5584 [==============================] - 0s 52us/step - loss: 0.1525 - acc: 0.9495 - val_loss: 1.3519 - val_acc: 0.7834\n",
      "Epoch 23/30\n",
      "5584/5584 [==============================] - 0s 51us/step - loss: 0.1469 - acc: 0.9524 - val_loss: 1.3204 - val_acc: 0.7822\n",
      "Epoch 24/30\n",
      "5584/5584 [==============================] - 0s 52us/step - loss: 0.1413 - acc: 0.9513 - val_loss: 1.2846 - val_acc: 0.7860\n",
      "Epoch 25/30\n",
      "5584/5584 [==============================] - 0s 51us/step - loss: 0.1379 - acc: 0.9522 - val_loss: 1.3382 - val_acc: 0.7864\n",
      "Epoch 26/30\n",
      "5584/5584 [==============================] - 0s 51us/step - loss: 0.1272 - acc: 0.9592 - val_loss: 1.4629 - val_acc: 0.7851\n",
      "Epoch 27/30\n",
      "5584/5584 [==============================] - 0s 54us/step - loss: 0.1204 - acc: 0.9604 - val_loss: 1.3755 - val_acc: 0.7855\n",
      "Epoch 28/30\n",
      "5584/5584 [==============================] - 0s 53us/step - loss: 0.1243 - acc: 0.9568 - val_loss: 1.4544 - val_acc: 0.7822\n",
      "Epoch 29/30\n",
      "5584/5584 [==============================] - 0s 55us/step - loss: 0.1094 - acc: 0.9604 - val_loss: 1.4368 - val_acc: 0.7872\n",
      "Epoch 30/30\n",
      "5584/5584 [==============================] - 0s 53us/step - loss: 0.1112 - acc: 0.9583 - val_loss: 1.4778 - val_acc: 0.7793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89b2ca5390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape = (MAX_SEQUENCE_LENGTH,), dtype = 'int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "x = Conv1D(64, 5, activation = 'relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "preds = Dense(46, activation = 'sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "print(model.summary())\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data = (X_val, y_val),\n",
    "          epochs = 30, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994/1994 [==============================] - 0s 62us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5933833050512622, 0.7472417251755266]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 300, 300)          9294900   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 46)                5934      \n",
      "=================================================================\n",
      "Total params: 9,520,482\n",
      "Trainable params: 225,582\n",
      "Non-trainable params: 9,294,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5584 samples, validate on 2392 samples\n",
      "Epoch 1/30\n",
      "5584/5584 [==============================] - 11s 2ms/step - loss: 2.6388 - acc: 0.3730 - val_loss: 2.0681 - val_acc: 0.4741\n",
      "Epoch 2/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 2.0111 - acc: 0.5016 - val_loss: 1.8530 - val_acc: 0.5305\n",
      "Epoch 3/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 1.8402 - acc: 0.5253 - val_loss: 1.5745 - val_acc: 0.6041\n",
      "Epoch 4/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 1.6040 - acc: 0.5963 - val_loss: 1.4745 - val_acc: 0.6104\n",
      "Epoch 5/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 1.5209 - acc: 0.6227 - val_loss: 1.3778 - val_acc: 0.6593\n",
      "Epoch 6/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 1.4041 - acc: 0.6508 - val_loss: 1.2635 - val_acc: 0.6781\n",
      "Epoch 7/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 1.3221 - acc: 0.6746 - val_loss: 1.2022 - val_acc: 0.7044\n",
      "Epoch 8/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 1.2771 - acc: 0.6884 - val_loss: 1.1708 - val_acc: 0.7174\n",
      "Epoch 9/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 1.1963 - acc: 0.7086 - val_loss: 1.0900 - val_acc: 0.7362\n",
      "Epoch 10/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 1.1316 - acc: 0.7233 - val_loss: 1.0475 - val_acc: 0.7471\n",
      "Epoch 11/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 1.0709 - acc: 0.7443 - val_loss: 1.0004 - val_acc: 0.7663\n",
      "Epoch 12/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 1.0350 - acc: 0.7516 - val_loss: 0.9773 - val_acc: 0.7684\n",
      "Epoch 13/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.9808 - acc: 0.7625 - val_loss: 0.9253 - val_acc: 0.7784\n",
      "Epoch 14/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.9275 - acc: 0.7731 - val_loss: 0.9004 - val_acc: 0.7847\n",
      "Epoch 15/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.8819 - acc: 0.7864 - val_loss: 0.8691 - val_acc: 0.7943\n",
      "Epoch 16/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.8356 - acc: 0.7958 - val_loss: 0.8484 - val_acc: 0.7985\n",
      "Epoch 17/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.8075 - acc: 0.8027 - val_loss: 0.8284 - val_acc: 0.8073\n",
      "Epoch 18/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.7850 - acc: 0.8093 - val_loss: 0.8011 - val_acc: 0.8098\n",
      "Epoch 19/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.7537 - acc: 0.8148 - val_loss: 0.7879 - val_acc: 0.8102\n",
      "Epoch 20/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.7169 - acc: 0.8261 - val_loss: 0.7797 - val_acc: 0.8156\n",
      "Epoch 21/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.6840 - acc: 0.8281 - val_loss: 0.7452 - val_acc: 0.8282\n",
      "Epoch 22/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.6653 - acc: 0.8406 - val_loss: 0.7278 - val_acc: 0.8315\n",
      "Epoch 23/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.6309 - acc: 0.8490 - val_loss: 0.7169 - val_acc: 0.8324\n",
      "Epoch 24/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.6002 - acc: 0.8496 - val_loss: 0.7042 - val_acc: 0.8403\n",
      "Epoch 25/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.5776 - acc: 0.8607 - val_loss: 0.7058 - val_acc: 0.8386\n",
      "Epoch 26/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.5563 - acc: 0.8655 - val_loss: 0.6903 - val_acc: 0.8436\n",
      "Epoch 27/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.5332 - acc: 0.8693 - val_loss: 0.6813 - val_acc: 0.8495\n",
      "Epoch 28/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.5134 - acc: 0.8759 - val_loss: 0.6864 - val_acc: 0.8462\n",
      "Epoch 29/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.4922 - acc: 0.8825 - val_loss: 0.6782 - val_acc: 0.8516\n",
      "Epoch 30/30\n",
      "5584/5584 [==============================] - 10s 2ms/step - loss: 0.4824 - acc: 0.8802 - val_loss: 0.6770 - val_acc: 0.8495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89be52bd68>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape = (MAX_SEQUENCE_LENGTH,), dtype = 'int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "units = 128\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "layer1 = LSTM(units,\n",
    "    dropout = 0.2,\n",
    "    recurrent_dropout = 0.2,\n",
    "    return_sequences = False)\n",
    "x = layer1(embedded_sequences)\n",
    "\n",
    "final_layer = Dense(46, activation = 'softmax')\n",
    "preds = final_layer(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "print(model.summary())\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data = (X_val, y_val),\n",
    "          epochs = 30, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994/1994 [==============================] - 6s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7196521676531288, 0.8340020060778381]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
